{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Bayes' theorem?\n",
        "\n",
        "Bayes' theorem, also called Bayes' rule or Bayes' law, is a formula in statistics used to calculate the conditional probability of an event happening, given that another event has already occurred. In simpler terms, it helps you revise the probability of something being true after you have some new evidence.\n",
        "\n",
        "Q2. What is the formula for Bayes' theorem?\n",
        "\n",
        "The formula can look a bit complex, but it breaks down like this:\n",
        "\n",
        "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
        "\n",
        "Here's what each part represents:\n",
        "\n",
        "P(A|B): This is the probability of event A happening, given that event B has already happened (what we're trying to solve for).\n",
        "P(B|A): This is the probability of event B happening, given that event A has happened (how likely evidence B is if A is true).\n",
        "P(A): This is the initial probability of event A happening before you considered B (prior probability).\n",
        "P(B): This is the total probability of event B happening, regardless of A (sometimes called marginal probability).\n",
        "Q3. How is Bayes' theorem used in practice?\n",
        "\n",
        "Bayes' theorem has a wide range of applications. Here are some examples:\n",
        "\n",
        "Medical diagnosis: Doctors can use it to calculate the probability of a patient having a specific disease based on their symptoms and test results.\n",
        "Spam filtering: Email filters use Bayes' theorem to identify spam emails based on keywords and other characteristics.\n",
        "Machine learning: It's a fundamental concept in Bayesian classification, where algorithms learn and adapt based on new data.\n",
        "Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
        "\n",
        "Bayes' theorem directly deals with conditional probability. It allows you to calculate the probability of one event (A) considering the occurrence of another event (B). Essentially, it refines the probability of A after you have information about B.\n",
        "\n",
        "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
        "\n",
        "Naive Bayes classifiers are a type of algorithm based on Bayes' theorem. There are different variations depending on the type of features used (Bernoulli, Multinomial, Gaussian). The choice depends on your data:\n",
        "\n",
        "Bernoulli Naive Bayes: Use this if your features are binary (yes/no, true/false).\n",
        "Multinomial Naive Bayes: This is suitable for features with discrete values like word counts in text classification.\n",
        "Gaussian Naive Bayes: This is ideal for features that follow a normal distribution (bell-shaped curve).\n",
        "\n",
        "Here's how to classify the new instance (X1 = 3, X2 = 4) using Naive Bayes:\n",
        "\n",
        "1. Calculate Class Probabilities:\n",
        "\n",
        "Since we're told the prior probabilities are equal for class A and B, we can simply assign a probability of 0.5 to each class (assuming there are only classes A and B).\n",
        "\n",
        "P(A) = 0.5\n",
        "P(B) = 0.5\n",
        "\n",
        "2. Calculate Feature Probabilities:\n",
        "\n",
        "We need to find the probabilities of the new instance's features (X1 = 3 and X2 = 4) for each class (A and B).\n",
        "\n",
        "For Class A:\n",
        "\n",
        "P(X1 = 3 | A) = Frequency of X1 = 3 in Class A / Total instances in Class A = 4 / 17\n",
        "P(X2 = 4 | A) = Frequency of X2 = 4 in Class A / Total instances in Class A = 3 / 17\n",
        "For Class B:\n",
        "\n",
        "P(X1 = 3 | B) = Frequency of X1 = 3 in Class B / Total instances in Class B = 1 / 7\n",
        "P(X2 = 4 | B) = Frequency of X2 = 4 in Class B / Total instances in Class B = 3 / 7\n",
        "3. Apply Naive Bayes Theorem (assuming independence):\n",
        "\n",
        "Naive Bayes assumes features are independent. Therefore, to find the probability of the new instance belonging to a class, we multiply the individual feature probabilities for that class.\n",
        "\n",
        "P(A | X1 = 3, X2 = 4) = P(X1 = 3 | A) * P(X2 = 4 | A) * P(A)\n",
        "P(B | X1 = 3, X2 = 4) = P(X1 = 3 | B) * P(X2 = 4 | B) * P(B)\n",
        "\n",
        "4. Compare Probabilities and Classify:\n",
        "\n",
        "Calculate the probabilities for each class using the formulas from step 3.\n",
        "The class with the higher probability is the predicted class for the new instance.\n",
        "5. Determine the Class:\n",
        "\n",
        "Without actual data values, we cannot calculate the final probabilities. However, based on the information given:\n",
        "\n",
        "Class A has a higher frequency of X1 = 3 compared to Class B.\n",
        "Both classes have the same frequency of X2 = 4.\n",
        "Since the prior probabilities are equal (0.5) and X2 doesn't significantly influence the outcome in this scenario,  Class A is likely to have a higher overall probability due to the higher frequency of X1 = 3.\n",
        "\n",
        "Therefore, based on the limited information, Naive Bayes would likely predict the new instance belongs to Class A."
      ],
      "metadata": {
        "id": "l0y3s5gAE7fh"
      }
    }
  ]
}